{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Skillfactory---Практический-Machine-Learning\" data-toc-modified-id=\"Skillfactory---Практический-Machine-Learning-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Skillfactory - Практический Machine Learning</a></div><div class=\"lev2 toc-item\"><a href=\"#05/03/2018---Композиции-алгоритмов\" data-toc-modified-id=\"05/03/2018---Композиции-алгоритмов-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>05/03/2018 - Композиции алгоритмов</a></div><div class=\"lev2 toc-item\"><a href=\"#Но-сначала:-Cluster-Validity-and-Quality-Measures\" data-toc-modified-id=\"Но-сначала:-Cluster-Validity-and-Quality-Measures-12\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Но сначала: Cluster Validity and Quality Measures</a></div><div class=\"lev2 toc-item\"><a href=\"#Оценка-качества-кластеризации-при-известном-groud-truth\" data-toc-modified-id=\"Оценка-качества-кластеризации-при-известном-groud-truth-13\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Оценка качества кластеризации при известном groud truth</a></div><div class=\"lev4 toc-item\"><a href=\"#Rand-Index\" data-toc-modified-id=\"Rand-Index-1301\"><span class=\"toc-item-num\">1.3.0.1&nbsp;&nbsp;</span>Rand Index</a></div><div class=\"lev4 toc-item\"><a href=\"#Rand-Index\" data-toc-modified-id=\"Rand-Index-1302\"><span class=\"toc-item-num\">1.3.0.2&nbsp;&nbsp;</span>Rand Index</a></div><div class=\"lev2 toc-item\"><a href=\"#Precision,-Recall,-F-measure\" data-toc-modified-id=\"Precision,-Recall,-F-measure-14\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Precision, Recall, F-measure</a></div><div class=\"lev2 toc-item\"><a href=\"#Меры-валидности-кластеров\" data-toc-modified-id=\"Меры-валидности-кластеров-15\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Меры валидности кластеров</a></div><div class=\"lev3 toc-item\"><a href=\"#Критерий-Silhouette\" data-toc-modified-id=\"Критерий-Silhouette-151\"><span class=\"toc-item-num\">1.5.1&nbsp;&nbsp;</span>Критерий Silhouette</a></div><div class=\"lev3 toc-item\"><a href=\"#Dunn-Index\" data-toc-modified-id=\"Dunn-Index-152\"><span class=\"toc-item-num\">1.5.2&nbsp;&nbsp;</span>Dunn Index</a></div><div class=\"lev3 toc-item\"><a href=\"#Davies–Bouldin-Index\" data-toc-modified-id=\"Davies–Bouldin-Index-153\"><span class=\"toc-item-num\">1.5.3&nbsp;&nbsp;</span>Davies–Bouldin Index</a></div><div class=\"lev3 toc-item\"><a href=\"#FYI\" data-toc-modified-id=\"FYI-154\"><span class=\"toc-item-num\">1.5.4&nbsp;&nbsp;</span>FYI</a></div><div class=\"lev1 toc-item\"><a href=\"#Композиции-алгоритмов\" data-toc-modified-id=\"Композиции-алгоритмов-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Композиции алгоритмов</a></div><div class=\"lev2 toc-item\"><a href=\"#Bagging-и-Случайный-лес-(Random-Forest)\" data-toc-modified-id=\"Bagging-и-Случайный-лес-(Random-Forest)-21\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Bagging и Случайный лес (Random Forest)</a></div><div class=\"lev2 toc-item\"><a href=\"#Почему-усреднение-работает?\" data-toc-modified-id=\"Почему-усреднение-работает?-22\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Почему усреднение работает?</a></div><div class=\"lev2 toc-item\"><a href=\"#Данные-об-оттоке-из-игры\" data-toc-modified-id=\"Данные-об-оттоке-из-игры-23\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Данные об оттоке из игры</a></div><div class=\"lev3 toc-item\"><a href=\"#Качество-на-одном-дереве\" data-toc-modified-id=\"Качество-на-одном-дереве-231\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Качество на одном дереве</a></div><div class=\"lev3 toc-item\"><a href=\"#Бэггинг-над-деревьями\" data-toc-modified-id=\"Бэггинг-над-деревьями-232\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>Бэггинг над деревьями</a></div><div class=\"lev3 toc-item\"><a href=\"#Случайных-лес\" data-toc-modified-id=\"Случайных-лес-233\"><span class=\"toc-item-num\">2.3.3&nbsp;&nbsp;</span>Случайных лес</a></div><div class=\"lev2 toc-item\"><a href=\"#Разные-фишки\" data-toc-modified-id=\"Разные-фишки-24\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Разные фишки</a></div><div class=\"lev3 toc-item\"><a href=\"#Бэггинг-можно-делать-не-только-над-деревьями\" data-toc-modified-id=\"Бэггинг-можно-делать-не-только-над-деревьями-241\"><span class=\"toc-item-num\">2.4.1&nbsp;&nbsp;</span>Бэггинг можно делать не только над деревьями</a></div><div class=\"lev3 toc-item\"><a href=\"#Листья-деревьев-как-признаки!\" data-toc-modified-id=\"Листья-деревьев-как-признаки!-242\"><span class=\"toc-item-num\">2.4.2&nbsp;&nbsp;</span>Листья деревьев как признаки!</a></div><div class=\"lev2 toc-item\"><a href=\"#Бустинг\" data-toc-modified-id=\"Бустинг-25\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Бустинг</a></div><div class=\"lev3 toc-item\"><a href=\"#Формальное-описание-алгоритма-AdaBoost\" data-toc-modified-id=\"Формальное-описание-алгоритма-AdaBoost-251\"><span class=\"toc-item-num\">2.5.1&nbsp;&nbsp;</span>Формальное описание алгоритма AdaBoost</a></div><div class=\"lev4 toc-item\"><a href=\"#Обозначения\" data-toc-modified-id=\"Обозначения-2511\"><span class=\"toc-item-num\">2.5.1.1&nbsp;&nbsp;</span>Обозначения</a></div><div class=\"lev4 toc-item\"><a href=\"#Конечное-предсказание\" data-toc-modified-id=\"Конечное-предсказание-2512\"><span class=\"toc-item-num\">2.5.1.2&nbsp;&nbsp;</span>Конечное предсказание</a></div><div class=\"lev4 toc-item\"><a href=\"#Алгоритм\" data-toc-modified-id=\"Алгоритм-2513\"><span class=\"toc-item-num\">2.5.1.3&nbsp;&nbsp;</span>Алгоритм</a></div><div class=\"lev3 toc-item\"><a href=\"#Демо\" data-toc-modified-id=\"Демо-252\"><span class=\"toc-item-num\">2.5.2&nbsp;&nbsp;</span>Демо</a></div><div class=\"lev3 toc-item\"><a href=\"#Применим-на-наших-данных\" data-toc-modified-id=\"Применим-на-наших-данных-253\"><span class=\"toc-item-num\">2.5.3&nbsp;&nbsp;</span>Применим на наших данных</a></div><div class=\"lev2 toc-item\"><a href=\"#Градиентный-бустинг\" data-toc-modified-id=\"Градиентный-бустинг-26\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Градиентный бустинг</a></div><div class=\"lev3 toc-item\"><a href=\"#Немного-формальности\" data-toc-modified-id=\"Немного-формальности-261\"><span class=\"toc-item-num\">2.6.1&nbsp;&nbsp;</span>Немного формальности</a></div><div class=\"lev3 toc-item\"><a href=\"#Демо\" data-toc-modified-id=\"Демо-262\"><span class=\"toc-item-num\">2.6.2&nbsp;&nbsp;</span>Демо</a></div><div class=\"lev4 toc-item\"><a href=\"#Особенности\" data-toc-modified-id=\"Особенности-2621\"><span class=\"toc-item-num\">2.6.2.1&nbsp;&nbsp;</span>Особенности</a></div><div class=\"lev3 toc-item\"><a href=\"#Попытка-интерпретации---partial-dependency-plot\" data-toc-modified-id=\"Попытка-интерпретации---partial-dependency-plot-263\"><span class=\"toc-item-num\">2.6.3&nbsp;&nbsp;</span>Попытка интерпретации - partial dependency plot</a></div><div class=\"lev1 toc-item\"><a href=\"#Стэкинг-и-Блендинг\" data-toc-modified-id=\"Стэкинг-и-Блендинг-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Стэкинг и Блендинг</a></div><div class=\"lev3 toc-item\"><a href=\"#Схема-классического-блендинга\" data-toc-modified-id=\"Схема-классического-блендинга-301\"><span class=\"toc-item-num\">3.0.1&nbsp;&nbsp;</span>Схема классического блендинга</a></div><div class=\"lev3 toc-item\"><a href=\"#Схема-классического-стекинга\" data-toc-modified-id=\"Схема-классического-стекинга-302\"><span class=\"toc-item-num\">3.0.2&nbsp;&nbsp;</span>Схема классического стекинга</a></div><div class=\"lev3 toc-item\"><a href=\"#Стэкинг-франкенштейн\" data-toc-modified-id=\"Стэкинг-франкенштейн-303\"><span class=\"toc-item-num\">3.0.3&nbsp;&nbsp;</span>Стэкинг франкенштейн</a></div><div class=\"lev2 toc-item\"><a href=\"#Полезные-ссылки\" data-toc-modified-id=\"Полезные-ссылки-31\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Полезные ссылки</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skillfactory - Практический Machine Learning\n",
    "## 05/03/2018 - Композиции алгоритмов\n",
    "\n",
    "<center> Шестаков Андрей </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from ipywidgets import interact, IntSlider, fixed, FloatSlider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Но сначала: Cluster Validity and Quality Measures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Оценка качества кластеризации при известном groud truth\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Rand Index\n",
    "\n",
    "$$ \\text{Rand}(\\hat{\\pi},\\pi^*) = \\frac{a + d}{a + b + c + d} \\text{,}$$\n",
    "где \n",
    "* $a$ - количество пар объектов, находящихся в одинаковых кластерах в $\\hat{\\pi}$ и\n",
    "$\\pi^*$, \n",
    "* $b$ ($c$) - количество пар объектов в одном и том же кластере в  $\\hat{\\pi}$ ($\\pi^*$), но в разных в  $\\pi^*$ ($\\hat{\\pi}$)\n",
    "* $d$ - количество пар объектов в разных кластерах в $\\hat{\\pi}$ и $\\pi^*$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Rand Index\n",
    "\n",
    "$$ \\text{Rand}(\\hat{\\pi},\\pi^*) = \\frac{tp + tn}{tp + fp + fn + tn} \\text{,}$$\n",
    "где \n",
    "* $tp$ - количество пар объектов, находящихся в одинаковых кластерах в $\\hat{\\pi}$ и\n",
    "$\\pi^*$, \n",
    "* $fp$ ($fn$) - количество пар объектов в одном и том же кластере в  $\\hat{\\pi}$ ($\\pi^*$), но в разных в  $\\pi^*$ ($\\hat{\\pi}$)\n",
    "* $tn$ - количество пар объектов в разных кластерах в $\\hat{\\pi}$ и $\\pi^*$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Adjusted Rand Index** - корректировка Rand index:\n",
    "\n",
    "$$\\text{ARI}(\\hat{\\pi},\\pi^*)   = \\frac{\\text{Rand}(\\hat{\\pi},\\pi^*) - \\text{Expected}}{\\text{Max} - \\text{Expected}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Precision, Recall, F-measure\n",
    "* $\\text{Precision}(\\hat{\\pi},\\pi^*)  = \\frac{tp}{tp+fn}$\n",
    "* $\\text{Recall}(\\hat{\\pi},\\pi^*)  = \\frac{tp}{tp+fp}$\n",
    "* $\\text{F-measure}(\\hat{\\pi},\\pi^*)  = \\frac{2\\cdot Precision \\cdot Recall}{Precision + Recall}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adjusted_rand_score(y, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.crosstab(y, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2)\n",
    "\n",
    "ax[0].scatter(X[:,0], X[:,2], c=y)\n",
    "ax[1].scatter(X[:,0], X[:,2], c=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Меры валидности кластеров\n",
    "\n",
    "* Измеряют полученое разбиения по отношению к качествам хорошей кластеризации\n",
    "    * Компактность объектов внутри кластера\n",
    "    * Разделимость кластеров друг от друга"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Критерий Silhouette\n",
    "\n",
    "Пусть дана кластеризация в $K$ кластеров, и объект $i$ попал в $C_k$\n",
    "\n",
    "* $a(i)$ -- среднее расстояние от $i$ объекта до объектов из $C_k$\n",
    "* $b(i) = min_{j \\neq k} b_j(i)$,  где $b_j(i)$ -- среднее расстояние от $i$ объекта до объектов из $C_j$\n",
    "$$\n",
    "silhouette(i) = \\frac{b(i) - a(i)}{\\max(a(i), b(i))}\n",
    "$$\n",
    "Средний silhouette для всех точек из $\\mathbf{X}$ является критерием качества кластеризации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='img/sil1.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='img/sil2.png'></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_samples, silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 4\n",
    "kmeans = KMeans(n_clusters=k)\n",
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_silhouette_values = silhouette_samples(X, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1,1)\n",
    "y_lower = 10\n",
    "for i in range(k):\n",
    "    # Aggregate the silhouette scores for samples belonging to\n",
    "    # cluster i, and sort them\n",
    "    ith_cluster_silhouette_values = \\\n",
    "        sample_silhouette_values[labels == i]\n",
    "\n",
    "    ith_cluster_silhouette_values.sort()\n",
    "\n",
    "    size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "    y_upper = y_lower + size_cluster_i\n",
    "\n",
    "    color = plt.cm.spectral(float(i) / k)\n",
    "    ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                      0, ith_cluster_silhouette_values,\n",
    "                      facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "    # Label the silhouette plots with their cluster numbers at the middle\n",
    "    ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "    # Compute the new y_lower for next plot\n",
    "    y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "ax1.set_ylabel(\"Cluster label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "silhouette_score(X, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Dunn Index\n",
    "\n",
    "Введем обозначения:\n",
    "* $\\delta(C_k,C_l) = \\min\\limits_{x_i\\in C_k, x_j \\in C_l}d(x_i, x_j) $ - расстояние между кластерами $C_k, C_l$\n",
    "* $\\Delta(C_k) = \\max\\limits_{x_i, x_j \\in C_k}d(x_i, x_j)$ - диаметр кластера\n",
    "\n",
    "Тогда \n",
    "$$DI = \\frac{\\min\\limits_{k \\neq l} \\delta(C_k, C_l)}{\\max\\limits_{(C_k)} \\Delta(C_k)} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Davies–Bouldin Index\n",
    "\n",
    "Введем обозначения\n",
    "* $S(C_k) = 1/|C_k|\\sum\\limits_{x_i \\in C_k} d(x_i, \\mu_{c_k})$ - разброс данных внутри кластера $C_k$\n",
    "\n",
    "$$ DB = \\frac{1}{K}\\sum\\limits_{C_k}\\max\\limits_{C_l \\neq C_k}\\frac{S(C_K) + S(C_l)}{d(\\mu_{c_k}, \\mu_{c_l})} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### FYI\n",
    "* [Обзор мер качества 1](http://www.sciencedirect.com/science/article/pii/S003132031200338X)\n",
    "* [Обзор мер качества 2](https://cran.r-project.org/web/packages/clusterCrit/vignettes/clusterCrit.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Композиции алгоритмов\n",
    "aka \n",
    "* Ансамбли моделей\n",
    "* Комитеты алгоритмов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bagging и Случайный лес (Random Forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Дерево решений очень чувствительно к данным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "def demo_2dec_tree():\n",
    "    fig, ax = plt.subplots(1,2)\n",
    "    fig.set_figheight(5)\n",
    "\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    X, y = make_moons(noise=0.3, random_state=42)\n",
    "    \n",
    "    # Dec Tree Stuff\n",
    "    for i in range(2):\n",
    "        idx = np.random.randint(0, X.shape[0], int(0.95*X.shape[0]))\n",
    "\n",
    "        X1 = X[idx, :]\n",
    "        y1 = y[idx]\n",
    "\n",
    "        ax[i].scatter(X1[:,0], X1[:, 1], c=y1)\n",
    "        ax[i].set_xlabel('$x_1$')\n",
    "        ax[i].set_ylabel('$x_2$')\n",
    "\n",
    "        # Dec Tree Stuff 2\n",
    "        tree = DecisionTreeClassifier(criterion='entropy', max_depth=5, random_state=123)\n",
    "        tree.fit(X1,y1)\n",
    "\n",
    "        x_range = np.linspace(X.min(), X.max(), 100)\n",
    "        xx1, xx2 = np.meshgrid(x_range, x_range)\n",
    "\n",
    "        Y = tree.predict(np.c_[xx1.ravel(), xx2.ravel()])\n",
    "        Y = Y.reshape(xx1.shape)\n",
    "\n",
    "        ax[i].contourf(xx1, xx2, Y, alpha=0.3)\n",
    "        ax[i].scatter(X[:,0], X[:,1],c=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "demo_2dec_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Bagging - это **параллельный** способ построения ансамбля.<br/>\n",
    "1. Обучающая выборка сэмплируется $k$ раз с помощью *bootstrap'a* (выборка с возвратом)\n",
    "2. На каждом сэмпле обучается отдельная **базовая модель**\n",
    "3. Ответы моделей усредняются (возможно с весом)\n",
    "<center><img src='http://image.slidesharecdn.com/ipbimprovingthemodelspredictivepowerwithensembleapproaches-121203224610-phpapp02/95/improving-the-models-predictive-power-with-ensemble-approaches-10-638.jpg?cb=1354575467' width='750'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Почему усреднение работает?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Какая высота у Эйфелевой башни?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Кто здесь леопард?\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-031e\"><img width=400 src='img/cat1.jpg'></th>\n",
    "    <th class=\"tg-031e\"><img width=500 src='img/cat2.jpg'></th>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Так же есть некоторые обобщения бэггинга:\n",
    "\n",
    "* Метод случайных подпространств - на шаге 1. сэмплируются не только объекты, но и подпространство признаков\n",
    "* Метод случайного леса - на каждом узле сэмплируется подпространство признаков\n",
    "\n",
    "В данном случае, на каждом сэмпле базовой моделью является дерево решений.<br/>\n",
    "Если вам нужно за минимальное время построить достаточно точную и устойчивую модель - это ваш вариант.\n",
    "\n",
    "\n",
    "<center><img src='img/rf-quote.png'></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def rf_demo(n_est=5):\n",
    "    rf = RandomForestClassifier(random_state=123, n_estimators=n_est)\n",
    "\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    X, y = make_moons(noise=0.3, random_state=123)\n",
    "    rf.fit(X, y)\n",
    "    \n",
    "    x_range = np.linspace(X.min(), X.max(), 100)\n",
    "    xx1, xx2 = np.meshgrid(x_range, x_range)\n",
    "    \n",
    "    \n",
    "    for tree in rf.estimators_:\n",
    "        y_hat = tree.predict(np.c_[xx1.ravel(), xx2.ravel()])\n",
    "        y_hat = y_hat.reshape(xx1.shape)\n",
    "\n",
    "        plt.contourf(xx1, xx2, y_hat, alpha=1.0/n_est)\n",
    "    plt.scatter(X[:,0], X[:,1], c=y)\n",
    "    \n",
    "    plt.xlabel('$x_1$')\n",
    "    plt.ylabel('$x_2$')\n",
    "    \n",
    "    plt.title('N estimators = %d' % n_est)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig = interact(rf_demo, n_est=IntSlider(min=1, max=101, value=1, step=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Данные об оттоке из игры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfx = pd.read_csv('data/x_train.csv', sep=';')\n",
    "dfy = pd.read_csv('data/y_train.csv', names=['target'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = dfx.values\n",
    "y = dfy.values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Качество на одном дереве"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=4, random_state=123)\n",
    "scoring = 'roc_auc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "depths = range(1, 10)\n",
    "_, tree_test_scores = validation_curve(model, X, y, param_name='max_depth', param_range=depths, \n",
    "                 scoring=scoring, cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(depths, tree_test_scores.mean(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Бэггинг над деревьями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = BaggingClassifier(DecisionTreeClassifier(), n_estimators=50, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, bag_test_scores = validation_curve(model, X, y, param_name='base_estimator__max_depth', param_range=depths, \n",
    "                 scoring=scoring, cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(depths, bag_test_scores.mean(axis=1), label='bag')\n",
    "plt.plot(depths, tree_test_scores.mean(axis=1), label='tree')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Случайных лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=123, n_estimators=50, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, forest_test_scores = validation_curve(model, X, y, param_name='max_depth', param_range=depths, \n",
    "                 scoring=scoring, cv=cv, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(depths, bag_test_scores.mean(axis=1), label='bag')\n",
    "plt.plot(depths, tree_test_scores.mean(axis=1), label='tree')\n",
    "plt.plot(depths, forest_test_scores.mean(axis=1), label='forest')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разные фишки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Бэггинг можно делать не только над деревьями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=4, random_state=123)\n",
    "scoring = 'roc_auc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "n_est =  [1, 10, 20, 50, 100]\n",
    "\n",
    "# base_pipe = Pipeline([\n",
    "#     ('scaler', StandardScaler()),\n",
    "#     ('clf', LogisticRegression())\n",
    "# ])\n",
    "\n",
    "for n in n_est:\n",
    "    model = BaggingClassifier(base_estimator=LogisticRegression(), \n",
    "                              n_estimators=n, \n",
    "                              bootstrap_features=False, n_jobs=1)\n",
    "    scores.append(cross_val_score(model, X, y, scoring=scoring, cv=cv, n_jobs=1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Листья деревьев как признаки!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед тем как применять линейную модель, можно собрать специальные признаки на основе деревьев.\n",
    "\n",
    "* Предварительно на данных строим лес из $T$ деревьем\n",
    "* Нумеруем листья каждого дерева от $0$ до $L_T$\n",
    "* Для каждого дерева собираем новый признак \"номер листа в котором оказался объект\"\n",
    "* Прогоняем новые признаки через OHE \n",
    "* Profit?\n",
    "\n",
    "Можно строить такое признаковое пространство с помощью случайного леса, но надо быть осторожным!\n",
    "\n",
    "Можно строить случайные деревья!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomTreesEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb = RandomTreesEmbedding(n_estimators=10, max_depth=5, random_state=123)\n",
    "emb.fit(X)\n",
    "\n",
    "# emb = RandomForestClassifier(n_estimators=10, max_depth=5, random_state=123)\n",
    "# emb.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_emb = emb.apply(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_emb[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_emb_sparse = emb.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_emb_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    ('tree_emb', RandomTreesEmbedding(n_estimators=50, max_depth=4)),\n",
    "    ('clf', LogisticRegression(C=0.1))\n",
    "])\n",
    "\n",
    "simple_model = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', LogisticRegression(C=0.1))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(model, X, y, scoring=scoring, cv=cv, n_jobs=-1)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(simple_model, X, y, scoring=scoring, cv=cv, n_jobs=-1)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Бустинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boosting, в отличие от bagging'а - это последовательный способ построения композиции моделей.\n",
    "\n",
    "Мы постоянно работаем с одним и тем же набором данных, **но** на каждом шаге строим новую базовую модель, которая учитывает ошибки предыдущей модели.<br\\>По большому счету, бустинг-алгоритмы отличаются лишь тем, как в них заложен учет этих самых ошибок.\n",
    "\n",
    "Например в методе **AdaBoost** каждому объекту присваивается вес, который изменяется в зависимости от того, ошиблась ли на нем очередная композиция базовых алгоритмов или нет. Так же веса имеются и у самих базовых моделей, которые штрафуют их за плохие предсказания. Для задачи классификации этот процесс можно проиллюстрировать следующим образом:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src='https://s9.postimg.org/lq3lethhr/boosting.png' width='850'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Формальное описание алгоритма AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обозначения\n",
    "Введем следующие обозначения:\n",
    "* $t_k$ - базовый классификатор, полученный на шаге $k$\n",
    "* $\\alpha_k$ - вес базового классификатора, полученного на шаге $k$\n",
    "* $w_k(i)$ - веса объектов на шаге $k$\n",
    "* $x_i$ - $i$-й объект, $i = 1, \\dots, N$\n",
    "* $y_i=\\{-1, 1\\}$ - метки класса для $i$-го объекта \n",
    "\n",
    "#### Конечное предсказание\n",
    "Конечное предсказание получается из взвешенной комбинации предсказания базовых моделей:\n",
    "$$ T(x^*) = sign(\\sum\\limits^{K}_{k=1}\\alpha_kt_k(x^*)) $$\n",
    "\n",
    "Наша цель - минимизировать количество ошибок на всей выборке ..\n",
    "\n",
    "$$ E_T = \\frac{1}{N}\\sum\\limits_{i=1}^N [T(x_i) \\neq y_i] $$\n",
    "\n",
    ".. которые мы мажорируем экспонентой =)\n",
    "\n",
    "$$ E_T = \\frac{1}{N}\\sum\\limits_{i=1}^N [T(x_i) \\neq y_i] \\leq \\frac{1}{N}\\sum\\limits_{i=1}^N e^{(-y_i\\sum_k\\alpha_kt_k(x_i))} $$\n",
    "\n",
    "Если мы посчитаем ошибки $E_1, E_2, E_3,...$ на каждом шаге, то это даст нам правило для обновления весов объектов. <br\\>\n",
    "А если мы посчитаем производную ошибки $E_t$ по $\\alpha_t$, то это даст нам правило для обновления весов базовых моделей. <br\\>\n",
    "\n",
    "#### Алгоритм\n",
    "Алгоритм обучения **Discrete AdaBoost**:\n",
    "\n",
    "* Инициализируем веса объектов $w_1(i) = \\frac{1}{N}$ \n",
    "* Для $k = 1..K$\n",
    "    * Обучить классификатор $t_k(x) \\in \\{-1, 1\\}$ используя веса объектов $w(i)_k$\n",
    "    * Вычислить взвешенную ошибку $\\epsilon = \\frac{\\sum_i w_{k}(i)[y_i \\neq t_k(x_i) ]}{\\sum_i w_{k}(i)}$\n",
    "    * Вычислить вес базовой модели $\\alpha_k = \\ln\\frac{1-\\epsilon}{\\epsilon}$\n",
    "    * Пересчитать веса объектов $w_{k+1}(i) = \\frac{w_{k}(i) e^{-\\alpha_k y_i t_k(x_i)}}{W}$, $i = 1, \\dots, N$,где $W = \\sum_i w_k(i) e^{-\\alpha_k y_i t_k(x_i)}$ - нормировочная константа.\n",
    "* $T(x) = sign(\\sum_k \\alpha_k t_k(x))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Демо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "def ada_demo(n_est=1):\n",
    "\n",
    "    ada = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1,), n_estimators=n_est, learning_rate=0.1)\n",
    "    ada.fit(X_moons, y_moons)\n",
    "    \n",
    "\n",
    "    plt.figure(figsize=(7,5))\n",
    "\n",
    "    xx1, xx2 = np.meshgrid(np.arange(-1.5, 2.5, 0.1),\n",
    "                           np.arange(-1, 1.5, 0.1))\n",
    "\n",
    "    y_hat = ada.predict(np.c_[xx1.ravel(), xx2.ravel()])\n",
    "    \n",
    "    y_hat = y_hat.reshape(xx1.shape)\n",
    "\n",
    "    plt.title('iteration = %d' % n_est )\n",
    "    plt.contourf(xx1, xx2, y_hat, cmap=plt.cm.Paired)\n",
    "    plt.scatter(X_moons[:, 0], X_moons[:, 1], c=y_moons)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_moons, y_moons = make_moons(noise=0.1)\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.scatter(X_moons[:, 0], X_moons[:, 1], c=y_moons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interact(ada_demo, n_est=IntSlider(min=1, max=150, value=1, step=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Применим на наших данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=123, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1), \n",
    "                         n_estimators=1000, \n",
    "                         learning_rate=0.01, \n",
    "                         random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ada.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_train = []\n",
    "scores_valid = []\n",
    "\n",
    "for y_pred in ada.staged_predict_proba(X_train):\n",
    "    scores_train.append(roc_auc_score(y_train, y_pred[:, 1]))\n",
    "    \n",
    "for y_pred in ada.staged_predict_proba(X_valid):\n",
    "    scores_valid.append(roc_auc_score(y_valid, y_pred[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(scores_train, label='train score')\n",
    "plt.plot(scores_valid, label='valid score')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(ada, X, y, scoring=scoring, cv=cv, n_jobs=-1)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Градиентный бустинг\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По своей структуре метод похож на алгоритм градиентного спуска - отсюда и такое название."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Немного формальности"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть дана дифференцируемая функция потерь $L(T_k(x), y)$ (для любой задачи - регрессии или классификации) <br\\>\n",
    "Функционал качества - $Q(T, y) = \\sum_iL(T_k(x_i), y_i) = \\sum_iL(T_{k-1}(x_i) + t_{k}(x_i), y_i)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "На секунду представим, что $t_{k}(x_i)$ - это просто вектор значений (значение для каждого объекта). \n",
    "\n",
    "Надо \"сдвинуть\" ответы предыдущей композиции $T_{k-1}$, так чтобы минимизировать функцию потерь (как в градиентном спуске)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Тогда задачу оптимизации $Q(T, y)$ можно решать простым градиентным методом:\n",
    "\n",
    "* $T_0$ - начальное приближение\n",
    "* Посчитаем градиент функции потерь $L$: $g_i = \\frac{\\partial L(T_{k-1}(x_i), y_i)}{\\partial T_{k-1}(x_i)}$, $i = 1, \\dots, N$ \n",
    "* $T_k = T_{k-1} - \\alpha g$ - делаем градиентный шаг\n",
    "\n",
    "\n",
    "Тогда $t_{k}(x) =  \\arg\\min\\limits_{t} \\sum\\limits_i(t_{k}(x_i) - g_i)^2$, не зависимо от функции потерь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Демо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "def grad_demo(n_est=1):\n",
    "    \n",
    "    np.random.seed(123)\n",
    "    X = np.random.uniform(-10, 10, 500)\n",
    "\n",
    "    y = np.sin(X)/X + np.random.normal(0, .1, 500)\n",
    "    plt.scatter(X, y)\n",
    "    \n",
    "\n",
    "    gbr = GradientBoostingRegressor(n_estimators=n_est, learning_rate=0.15)\n",
    "    gbr_full = GradientBoostingRegressor(n_estimators=200, learning_rate=0.15)\n",
    "    gbr.fit(X.reshape(-1,1), y)\n",
    "    gbr_full.fit(X.reshape(-1,1), y)\n",
    "    \n",
    "    x_range = np.linspace(X.min(), X.max(), 100).reshape((-1,1))\n",
    "\n",
    "    for y_hat in gbr.staged_predict(x_range):\n",
    "        plt.plot(x_range, y_hat, alpha=0.4, c='g')\n",
    "\n",
    "    y_hat = gbr_full.predict(x_range)\n",
    "    \n",
    "    plt.title('Estimators %d' % n_est)\n",
    "    plt.plot(x_range, y_hat, c='r')\n",
    "    plt.xlabel('x')\n",
    "    plt.xlabel('y')\n",
    "    plt.ylim((-0.5, 1.3))\n",
    "    plt.xlim(-11,11)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "interact(grad_demo, n_est=IntSlider(min=1, max=150, value=1, step=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Особенности\n",
    "* Последовательное обучение\n",
    "* Склонность к переобучению\n",
    "* Проблемы с интерпретацией"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Наибольший успех, а потому и популярность, получил градиентный бустинг на деревьях решений.\n",
    "\n",
    "На досуге обратите внимание на модель `xgboost`. Вводный курс по этой модели можно найти [тут](http://education.parrotprediction.teachable.com/p/practical-xgboost-in-python)\n",
    "\n",
    "Так же есть другая популярная реализация бустинга [LightGBM](https://github.com/Microsoft/LightGBM)\n",
    "\n",
    "И, конечно же, недавний [CatBoost](https://tech.yandex.ru/catboost/), [видео](https://youtu.be/Q_xa4RvnDcY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2)\n",
    "\n",
    "for lr in [0.02, 0.5, 1]:\n",
    "\n",
    "    model = GradientBoostingClassifier(n_estimators=300, max_depth=3,\n",
    "                                       learning_rate=lr, \n",
    "                                       random_state=123)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    scores_train = []\n",
    "    scores_valid = []\n",
    "\n",
    "    for y_pred in model.staged_predict_proba(X_train):\n",
    "        scores_train.append(roc_auc_score(y_train, y_pred[:, 1]))\n",
    "        \n",
    "    ax[0].plot(scores_train, label='lr={}'.format(lr))\n",
    "    ax[0].set_title('Train set')\n",
    "\n",
    "    for y_pred in model.staged_predict_proba(X_valid):\n",
    "        scores_valid.append(roc_auc_score(y_valid, y_pred[:, 1])) \n",
    "        \n",
    "    ax[1].plot(scores_valid, label='lr={}'.format(lr))\n",
    "    ax[1].set_title('Validation set')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier(n_estimators=300, max_depth=3,\n",
    "                                       learning_rate=0.02, \n",
    "                                       random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(model, X, y, scoring=scoring, cv=cv, n_jobs=-1)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp = pd.Series(index=dfx.columns, data=model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Попытка интерпретации - partial dependency plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble.partial_dependence import plot_partial_dependence\n",
    "from sklearn.ensemble.partial_dependence import partial_dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax =\\\n",
    "plot_partial_dependence(model, X_train, [0, 1, 3, (0,3)], \n",
    "                        feature_names=dfx.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pdp, axes = partial_dependence(model, [0], X=X_train, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(axes[0], pdp[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Стэкинг и Блендинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Схемы бэггинга и бустинка не гибкие. По сути, на каждом этапе обучается один и тот же алгоритм на немного измененных данных.\n",
    "\n",
    "Можно еще собирать ансамбли **разных моделей** и аггрегировать их результаты. Только не переобучиться бы.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Схема классического блендинга\n",
    "<center><img src='https://alexanderdyakonov.files.wordpress.com/2017/03/stacking.png?w=700'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Схема классического стекинга\n",
    "<center><img src='https://alexanderdyakonov.files.wordpress.com/2017/03/stacking-2b.png?w=700'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стэкинг франкенштейн\n",
    "\n",
    "<img src='https://kaggle2.blob.core.windows.net/forum-message-attachments/79598/2514/FINAL_ARCHITECTURE.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install vecstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from vecstack import stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = [\n",
    "    RandomForestClassifier(n_estimators=50, max_depth=5, random_state=123),\n",
    "    RandomForestClassifier(n_estimators=50, max_depth=10, random_state=123, max_features='log2'),\n",
    "    Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('clf', LogisticRegression())\n",
    "    ]),\n",
    "    Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('clf', KNeighborsClassifier(n_neighbors=11))\n",
    "    ]),\n",
    "    GaussianNB()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def roc_auc_score_cust(y_true, y_hat):\n",
    "    return roc_auc_score(y_true, y_hat[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "S_train, S_valid = stacking(models,\n",
    "                               X_train, y_train, X_valid,\n",
    "                               regression=False,\n",
    "                               mode='oof_pred_bag', \n",
    "                               needs_proba=True,\n",
    "                               metric=roc_auc_score_cust,\n",
    "                               n_folds=5,                \n",
    "                               stratified=True,          \n",
    "                               shuffle=True,             \n",
    "                               random_state=123,         \n",
    "                               verbose=2)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "last_model = GradientBoostingClassifier(n_estimators=300, max_depth=3,\n",
    "                                       learning_rate=0.01, \n",
    "                                       random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "last_model.fit(S_train, y_train)\n",
    "y_hat = last_model.predict_proba(S_valid)\n",
    "roc_auc_score(y_valid, y_hat[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    last_model.fit(X_train, y_train)\n",
    "    y_hat = model.predict_proba(X_valid)\n",
    "    score = roc_auc_score(y_valid, y_hat[:, 1])\n",
    "    print('{}: {}'.format(model.__str__().split('(')[0], score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Полезные ссылки\n",
    "\n",
    "* [Превью Градиентного Бустинга](http://arogozhnikov.github.io/2016/06/24/gradient_boosting_explained.html)\n",
    "* [Вводный курс по XGB](http://education.parrotprediction.teachable.com/p/practical-xgboost-in-python)\n",
    "* [CatBoost](https://tech.yandex.ru/catboost/)\n",
    "* [Kaggle про смешивание алгоритмов](http://blog.kaggle.com/2016/12/27/a-kagglers-guide-to-model-stacking-in-practice/)\n",
    "* [Пост про градиентный бустинг от А.Дьяконова](https://alexanderdyakonov.wordpress.com/2017/06/09/%d0%b3%d1%80%d0%b0%d0%b4%d0%b8%d0%b5%d0%bd%d1%82%d0%bd%d1%8b%d0%b9-%d0%b1%d1%83%d1%81%d1%82%d0%b8%d0%bd%d0%b3/)\n",
    "* [Пост про стекинг и блендинг от А.Дьяконова](https://alexanderdyakonov.wordpress.com/2017/03/10/c%D1%82%D0%B5%D0%BA%D0%B8%D0%BD%D0%B3-stacking-%D0%B8-%D0%B1%D0%BB%D0%B5%D0%BD%D0%B4%D0%B8%D0%BD%D0%B3-blending/)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "nav_menu": {},
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "347px",
    "width": "253px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": false,
   "threshold": 4,
   "toc_cell": true,
   "toc_position": {
    "height": "40px",
    "left": "952px",
    "right": "9.46667px",
    "top": "100px",
    "width": "182px"
   },
   "toc_section_display": "none",
   "toc_window_display": true,
   "widenNotebook": false
  },
  "toc_position": {
   "height": "40px",
   "left": "816px",
   "right": "38.6667px",
   "top": "0px",
   "width": "212px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
